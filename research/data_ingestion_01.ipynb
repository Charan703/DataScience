{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/Users/charantejakammari/Desktop/DataScience/research'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/Users/charantejakammari/Desktop/DataScience'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.chdir(\"../\")\n",
        "%pwd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Ingestion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "from pathlib import Path\n",
        "\n",
        "@dataclass()\n",
        "class DataIngestionConfig:\n",
        "    root_dir: Path\n",
        "    source_URL: str\n",
        "    local_data_file: Path\n",
        "    unzip_dir: Path\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.Data_Science.constants import *\n",
        "from src.Data_Science.utils.common import read_yaml, create_directories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ConfigurationManager:\n",
        "    def __init__(\n",
        "        self,\n",
        "        config_filepath = CONFIG_FILE_PATH,\n",
        "        params_filepath = PARAMS_FILE_PATH,\n",
        "        schema_filepath = SCHEMA_FILE_PATH):\n",
        "        self.config = read_yaml(config_filepath)\n",
        "        self.params = read_yaml(params_filepath)\n",
        "        self.schema = read_yaml(schema_filepath)\n",
        "        create_directories([self.config.artifacts_root])\n",
        "\n",
        "    def get_data_ingestion_config(self) -> DataIngestionConfig:\n",
        "        config = self.config.data_ingestion\n",
        "        create_directories([config.root_dir])\n",
        "        data_ingestion_config = DataIngestionConfig(\n",
        "            root_dir=config.root_dir,\n",
        "            source_URL=config.source_URL,\n",
        "            local_data_file=config.local_data_file,\n",
        "            unzip_dir=config.unzip_dir \n",
        "        )\n",
        "        return data_ingestion_config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "invalid syntax (3770094778.py, line 34)",
          "output_type": "error",
          "traceback": [
            "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 34\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mExtracts the zip file into the data directory\u001b[39m\n             ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import urllib.request\n",
        "from os.path import getsize\n",
        "import os\n",
        "from src.Data_Science import logger\n",
        "\n",
        "class DataIngestion:\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "\n",
        "    def download_file(self):\n",
        "        should_download = True\n",
        "\n",
        "        if os.path.exists(self.config.local_data_file):\n",
        "            try:\n",
        "                with zipfile.ZipFile(self.config.local_data_file, 'r') as existing_zip:\n",
        "                    existing_zip.testzip()\n",
        "                logger.info(f\"Valid file already exists of size: {getsize(self.config.local_data_file)}\")\n",
        "                should_download = False\n",
        "            except zipfile.BadZipFile:\n",
        "                logger.info(\"Existing file is not a valid zip. Re-downloading.\")\n",
        "                os.remove(self.config.local_data_file)\n",
        "\n",
        "        if should_download:\n",
        "            filename, headers = urllib.request.urlretrieve(\n",
        "                url=self.config.source_URL,\n",
        "                filename=self.config.local_data_file\n",
        "            )\n",
        "            logger.info(f\"{filename} downloaded!\")\n",
        "\n",
        "    def extract_zip_file(self):\n",
        "        \"\"\"\n",
        "        zip_file_path: str\n",
        "        Extracts the zip file into the data directory\n",
        "        Function returns None\n",
        "        \"\"\"\n",
        "        unzip_path = self.config.unzip_dir\n",
        "        os.makedirs(unzip_path, exist_ok=True)\n",
        "        try:\n",
        "            with zipfile.ZipFile(self.config.local_data_file, 'r') as zip_ref:\n",
        "                zip_ref.extractall(unzip_path)\n",
        "        except zipfile.BadZipFile as exc:\n",
        "            raise zipfile.BadZipFile(\"Downloaded file is not a valid zip. Check source_URL.\") from exc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2025-12-26 23:17:47,728: INFO: common: yaml file: config/config.yaml loaded successfully]\n",
            "[2025-12-26 23:17:47,730: INFO: common: yaml file: params.yaml loaded successfully]\n",
            "[2025-12-26 23:17:47,731: INFO: common: yaml file: schema.yaml loaded successfully]\n",
            "[2025-12-26 23:17:47,732: INFO: common: created directory at: artifacts]\n",
            "[2025-12-26 23:17:47,733: INFO: common: created directory at: artifacts/data_ingestion]\n",
            "[2025-12-26 23:17:47,901: INFO: 4018249200: artifacts/data_ingestion/data.zip downloaded!]\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    config = ConfigurationManager()\n",
        "    data_ingestion_config = config.get_data_ingestion_config()\n",
        "    data_ingestion = DataIngestion(config=data_ingestion_config)\n",
        "    data_ingestion.download_file()\n",
        "    data_ingestion.extract_zip_file()\n",
        "except Exception as e:\n",
        "    raise e"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv(\"artifacts/data_ingestion/winequality-red.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fixed acidity</th>\n",
              "      <th>volatile acidity</th>\n",
              "      <th>citric acid</th>\n",
              "      <th>residual sugar</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>free sulfur dioxide</th>\n",
              "      <th>total sulfur dioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>quality</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.9978</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.6</td>\n",
              "      <td>0.098</td>\n",
              "      <td>25.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>0.9968</td>\n",
              "      <td>3.20</td>\n",
              "      <td>0.68</td>\n",
              "      <td>9.8</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.04</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0.092</td>\n",
              "      <td>15.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0.9970</td>\n",
              "      <td>3.26</td>\n",
              "      <td>0.65</td>\n",
              "      <td>9.8</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.2</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.56</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.075</td>\n",
              "      <td>17.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0.9980</td>\n",
              "      <td>3.16</td>\n",
              "      <td>0.58</td>\n",
              "      <td>9.8</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.9978</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
              "0            7.4              0.70         0.00             1.9      0.076   \n",
              "1            7.8              0.88         0.00             2.6      0.098   \n",
              "2            7.8              0.76         0.04             2.3      0.092   \n",
              "3           11.2              0.28         0.56             1.9      0.075   \n",
              "4            7.4              0.70         0.00             1.9      0.076   \n",
              "\n",
              "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
              "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
              "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
              "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
              "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
              "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
              "\n",
              "   alcohol  quality  \n",
              "0      9.4        5  \n",
              "1      9.8        5  \n",
              "2      9.8        5  \n",
              "3      9.8        6  \n",
              "4      9.4        5  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1599 entries, 0 to 1598\n",
            "Data columns (total 12 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   fixed acidity         1599 non-null   float64\n",
            " 1   volatile acidity      1599 non-null   float64\n",
            " 2   citric acid           1599 non-null   float64\n",
            " 3   residual sugar        1599 non-null   float64\n",
            " 4   chlorides             1599 non-null   float64\n",
            " 5   free sulfur dioxide   1599 non-null   float64\n",
            " 6   total sulfur dioxide  1599 non-null   float64\n",
            " 7   density               1599 non-null   float64\n",
            " 8   pH                    1599 non-null   float64\n",
            " 9   sulphates             1599 non-null   float64\n",
            " 10  alcohol               1599 non-null   float64\n",
            " 11  quality               1599 non-null   int64  \n",
            "dtypes: float64(11), int64(1)\n",
            "memory usage: 150.0 KB\n"
          ]
        }
      ],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fixed acidity\n",
            "volatile acidity\n",
            "citric acid\n",
            "residual sugar\n",
            "chlorides\n",
            "free sulfur dioxide\n",
            "total sulfur dioxide\n",
            "density\n",
            "pH\n",
            "sulphates\n",
            "alcohol\n",
            "quality\n"
          ]
        }
      ],
      "source": [
        "for i in data.columns:\n",
        "    print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "fixed acidity           0\n",
              "volatile acidity        0\n",
              "citric acid             0\n",
              "residual sugar          0\n",
              "chlorides               0\n",
              "free sulfur dioxide     0\n",
              "total sulfur dioxide    0\n",
              "density                 0\n",
              "pH                      0\n",
              "sulphates               0\n",
              "alcohol                 0\n",
              "quality                 0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1599, 12)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "from pathlib import Path\n",
        "\n",
        "@dataclass()\n",
        "class DataValidationConfig:\n",
        "    root_dir: Path\n",
        "    STATUS_FILE: str\n",
        "    unzip_data_dir: Path\n",
        "    all_schema: dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.Data_Science.constants import *\n",
        "from src.Data_Science.utils.common import read_yaml, create_directories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ConfigurationManager:\n",
        "    def __init__(\n",
        "        self,\n",
        "        config_filepath = CONFIG_FILE_PATH,\n",
        "        params_filepath = PARAMS_FILE_PATH,\n",
        "        schema_filepath = SCHEMA_FILE_PATH):\n",
        "\n",
        "        self.config = read_yaml(config_filepath)\n",
        "        self.params = read_yaml(params_filepath)\n",
        "        self.schema = read_yaml(schema_filepath)\n",
        "\n",
        "        create_directories([self.config.artifacts_root])\n",
        "    \n",
        "    def get_data_validation_config(self) -> DataValidationConfig:\n",
        "        config = self.config.data_validation\n",
        "        schema = self.schema.COLUMNS\n",
        "\n",
        "        create_directories([config.root_dir])\n",
        "\n",
        "        data_validation_config = DataValidationConfig(\n",
        "            root_dir=config.root_dir,\n",
        "            STATUS_FILE=config.STATUS_FILE,\n",
        "            unzip_data_dir=config.unzip_data_dir,\n",
        "            all_schema=schema,\n",
        "        )\n",
        "\n",
        "        return data_validation_config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from src.Data_Science import logger\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "class DataValidation:\n",
        "    def __init__(self, config: DataValidationConfig):\n",
        "        self.config = config\n",
        "\n",
        "    def validate_all_columns(self) -> bool:\n",
        "        try:\n",
        "            validation_status = None\n",
        "\n",
        "            data = pd.read_csv(self.config.unzip_data_dir)\n",
        "            all_schema = self.config.all_schema.keys()\n",
        "            all_schema_datatypes = self.config.all_schema.values()\n",
        "\n",
        "            # loop that checks if all columns are present in the data and if all columns are of the correct datatype\n",
        "            for col, datatype in zip(all_schema, all_schema_datatypes):\n",
        "                if data[col].dtype != datatype:\n",
        "                    validation_status = False\n",
        "                    with open(self.config.STATUS_FILE, 'w') as f:\n",
        "                        f.write(f\"Validation status: {validation_status}\")\n",
        "                else:\n",
        "                    validation_status = True\n",
        "                    with open(self.config.STATUS_FILE, 'w') as f:\n",
        "                        f.write(f\"Validation status: {validation_status}\")\n",
        "\n",
        "            return validation_status\n",
        "\n",
        "        except Exception as e:\n",
        "            raise e"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2025-12-27 13:22:41,607: INFO: common: yaml file: config/config.yaml loaded successfully]\n",
            "[2025-12-27 13:22:41,608: INFO: common: yaml file: params.yaml loaded successfully]\n",
            "[2025-12-27 13:22:41,609: INFO: common: yaml file: schema.yaml loaded successfully]\n",
            "[2025-12-27 13:22:41,610: INFO: common: created directory at: artifacts]\n",
            "[2025-12-27 13:22:41,610: INFO: common: created directory at: artifacts/data_validation]\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    config = ConfigurationManager()\n",
        "    data_validation_config = config.get_data_validation_config()\n",
        "    data_validation = DataValidation(config=data_validation_config)\n",
        "    data_validation.validate_all_columns()\n",
        "except Exception as e:\n",
        "    raise e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Transformation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "from pathlib import Path\n",
        "\n",
        "@dataclass()\n",
        "class DataTransformationConfig:\n",
        "    root_dir: Path\n",
        "    data_path: Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir(\"../\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.Data_Science.constants import *\n",
        "from src.Data_Science.utils.common import read_yaml, create_directories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ConfigurationManager:\n",
        "    def __init__(\n",
        "        self,\n",
        "        config_filepath = CONFIG_FILE_PATH,\n",
        "        params_filepath = PARAMS_FILE_PATH,\n",
        "        schema_filepath = SCHEMA_FILE_PATH):\n",
        "\n",
        "        self.config = read_yaml(config_filepath)\n",
        "        self.params = read_yaml(params_filepath)\n",
        "        self.schema = read_yaml(schema_filepath)\n",
        "\n",
        "        create_directories([self.config.artifacts_root])\n",
        "    \n",
        "    def get_data_transformation_config(self) -> DataTransformationConfig:\n",
        "        config = self.config.data_transformation\n",
        "\n",
        "        create_directories([config.root_dir])\n",
        "\n",
        "        data_transformation_config = DataTransformationConfig(\n",
        "            root_dir=config.root_dir,\n",
        "            data_path=config.data_path,\n",
        "        )\n",
        "\n",
        "        return data_transformation_config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "class DataTransformation:\n",
        "    def __init__(self, config: DataTransformationConfig):\n",
        "        self.config = config\n",
        "\n",
        "    def train_test_splitting(self):\n",
        "        data = pd.read_csv(self.config.data_path)\n",
        "\n",
        "        data = data.drop_duplicates()\n",
        "\n",
        "        # Split the data into training and test sets. (0.75, 0.25) split.\n",
        "        train, test = train_test_split(data)\n",
        "\n",
        "        train.to_csv(os.path.join(self.config.root_dir, \"train.csv\"),index = False)\n",
        "        test.to_csv(os.path.join(self.config.root_dir, \"test.csv\"),index = False)\n",
        "\n",
        "        logger.info(\"Splited data into training and test sets\")\n",
        "        logger.info(train.shape)\n",
        "        logger.info(test.shape)\n",
        "\n",
        "        print(train.shape)\n",
        "        print(test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2025-12-27 13:49:14,982: INFO: common: yaml file: config/config.yaml loaded successfully]\n",
            "[2025-12-27 13:49:14,983: INFO: common: yaml file: params.yaml loaded successfully]\n",
            "[2025-12-27 13:49:14,985: INFO: common: yaml file: schema.yaml loaded successfully]\n",
            "[2025-12-27 13:49:14,985: INFO: common: created directory at: artifacts]\n",
            "[2025-12-27 13:49:14,986: INFO: common: created directory at: artifacts/data_transformation]\n",
            "[2025-12-27 13:49:14,998: INFO: 3107515286: Splited data into training and test sets]\n",
            "[2025-12-27 13:49:14,998: INFO: 3107515286: (1019, 12)]\n",
            "[2025-12-27 13:49:14,999: INFO: 3107515286: (340, 12)]\n",
            "(1019, 12)\n",
            "(340, 12)\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    config = ConfigurationManager()\n",
        "    data_transformation_config = config.get_data_transformation_config()\n",
        "    data_transformation = DataTransformation(config=data_transformation_config)\n",
        "    data_transformation.train_test_splitting()\n",
        "except Exception as e:\n",
        "    raise e"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/Users/charantejakammari/Desktop/DataScience'"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%pwd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "from pathlib import Path\n",
        "\n",
        "@dataclass()\n",
        "class ModelTrainerConfig:\n",
        "    root_dir: Path\n",
        "    train_data_path: Path\n",
        "    test_data_path: Path\n",
        "    model_name: str\n",
        "    alpha: float\n",
        "    l1_ratio: float\n",
        "    target_column: str"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.Data_Science.constants import *\n",
        "from src.Data_Science.utils.common import read_yaml, create_directories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ConfigurationManager:\n",
        "    def __init__(\n",
        "        self,\n",
        "        config_filepath = CONFIG_FILE_PATH,\n",
        "        params_filepath = PARAMS_FILE_PATH,\n",
        "        schema_filepath = SCHEMA_FILE_PATH):\n",
        "\n",
        "        self.config = read_yaml(config_filepath)\n",
        "        self.params = read_yaml(params_filepath)\n",
        "        self.schema = read_yaml(schema_filepath)\n",
        "\n",
        "        create_directories([self.config.artifacts_root])\n",
        "    \n",
        "    def get_model_trainer_config(self) -> ModelTrainerConfig:\n",
        "        config = self.config.model_trainer\n",
        "        params = self.params.ElasticNet\n",
        "        schema = self.schema.TARGET_COLUMN\n",
        "\n",
        "        create_directories([config.root_dir])\n",
        "\n",
        "        model_trainer_config = ModelTrainerConfig(\n",
        "            root_dir=config.root_dir,\n",
        "            train_data_path=config.train_data_path,\n",
        "            test_data_path=config.test_data_path,\n",
        "            model_name=config.model_name,\n",
        "            alpha=params.alpha,\n",
        "            l1_ratio=params.l1_ratio,\n",
        "            target_column=schema.name\n",
        "        )\n",
        "\n",
        "        return model_trainer_config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from src.Data_Science import logger\n",
        "from sklearn.linear_model import ElasticNet\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ModelTrainer:\n",
        "    def __init__(self, config: ModelTrainerConfig):\n",
        "        self.config = config\n",
        "\n",
        "    def train(self):\n",
        "        train_data = pd.read_csv(self.config.train_data_path)\n",
        "        test_data = pd.read_csv(self.config.test_data_path)\n",
        "\n",
        "        train_x = train_data.drop([self.config.target_column], axis=1)\n",
        "        test_x = test_data.drop([self.config.target_column], axis=1)\n",
        "        train_y = train_data[[self.config.target_column]]\n",
        "        test_y = test_data[[self.config.target_column]]\n",
        "\n",
        "        lr = ElasticNet(alpha=self.config.alpha, l1_ratio=self.config.l1_ratio, random_state=42)\n",
        "        lr.fit(train_x, train_y)\n",
        "\n",
        "        joblib.dump(lr, os.path.join(self.config.root_dir, self.config.model_name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2025-12-27 14:52:52,158: INFO: common: yaml file: config/config.yaml loaded successfully]\n",
            "[2025-12-27 14:52:52,160: INFO: common: yaml file: params.yaml loaded successfully]\n",
            "[2025-12-27 14:52:52,161: INFO: common: yaml file: schema.yaml loaded successfully]\n",
            "[2025-12-27 14:52:52,162: INFO: common: created directory at: artifacts]\n",
            "[2025-12-27 14:52:52,162: INFO: common: created directory at: artifacts/model_trainer]\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    config = ConfigurationManager()\n",
        "    model_trainer_config = config.get_model_trainer_config()\n",
        "    model_trainer_config = ModelTrainer(config=model_trainer_config)\n",
        "    model_trainer_config.train()\n",
        "except Exception as e:\n",
        "    raise e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"MLFLOW_TRACKING_URI\"] = \"https://dagshub.com/charanteja.kammari939/DataScience.mlflow\"\n",
        "os.environ[\"MLFLOW_TRACKING_USERNAME\"] = \"charanteja.kammari939\"\n",
        "os.environ[\"MLFLOW_TRACKING_PASSWORD\"] = \"ed4976ac03caf4f7fc7628a70a2e20927f62c4a5\"\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from pathlib import Path\n",
        "\n",
        "@dataclass()\n",
        "class ModelEvaluationConfig:\n",
        "    root_dir: Path\n",
        "    test_data_path: Path\n",
        "    model_path: Path\n",
        "    all_params: dict\n",
        "    metric_file_name: Path\n",
        "    target_column: str\n",
        "    mlflow_uri: str"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.Data_Science.constants import *\n",
        "from src.Data_Science.utils.common import read_yaml, create_directories, save_json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ConfigurationManager:\n",
        "    def __init__(\n",
        "        self,\n",
        "        config_filepath = CONFIG_FILE_PATH,\n",
        "        params_filepath = PARAMS_FILE_PATH,\n",
        "        schema_filepath = SCHEMA_FILE_PATH):\n",
        "\n",
        "        self.config = read_yaml(config_filepath)\n",
        "        self.params = read_yaml(params_filepath)\n",
        "        self.schema = read_yaml(schema_filepath)\n",
        "\n",
        "        create_directories([self.config.artifacts_root])\n",
        "    \n",
        "    def get_model_evaluation_config(self) -> ModelEvaluationConfig:\n",
        "        config = self.config.model_evaluation\n",
        "        params = self.params.ElasticNet\n",
        "        schema = self.schema.TARGET_COLUMN\n",
        "\n",
        "        create_directories([config.root_dir])\n",
        "\n",
        "        model_evaluation_config = ModelEvaluationConfig(\n",
        "            root_dir=config.root_dir,\n",
        "            test_data_path=config.test_data_path,\n",
        "            model_path=config.model_path,\n",
        "            all_params=params,\n",
        "            metric_file_name=config.metric_file_name,\n",
        "            target_column=schema.name,\n",
        "            mlflow_uri= \"https://dagshub.com/charanteja.kammari939/DataScience.mlflow\"\n",
        "        )\n",
        "\n",
        "        return model_evaluation_config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/charantejakammari/Desktop/DataScience/venv/lib/python3.11/site-packages/mlflow/utils/requirements_utils.py:12: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  import pkg_resources\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from urllib.parse import urlparse\n",
        "import mlflow\n",
        "import numpy as np\n",
        "import joblib\n",
        "import mlflow.sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ModelEvaluation:\n",
        "    def __init__(self, config: ModelEvaluationConfig):\n",
        "        self.config = config\n",
        "\n",
        "    def eval_metrics(self, actual, pred):\n",
        "        rmse = np.sqrt(mean_squared_error(actual, pred))\n",
        "        mae = mean_absolute_error(actual, pred)\n",
        "        r2 = r2_score(actual, pred)\n",
        "        return rmse, mae, r2\n",
        "\n",
        "    def log_into_mlflow(self):\n",
        "        test_data = pd.read_csv(self.config.test_data_path)\n",
        "        model = joblib.load(self.config.model_path)\n",
        "\n",
        "        test_x = test_data.drop([self.config.target_column], axis=1)\n",
        "        test_y = test_data[[self.config.target_column]]\n",
        "\n",
        "        mlflow.set_registry_uri(self.config.mlflow_uri)\n",
        "        tracking_url_type_store = urlparse(mlflow.get_tracking_uri()).scheme\n",
        "\n",
        "        with mlflow.start_run():\n",
        "            predicted_qualities = model.predict(test_x)\n",
        "\n",
        "            (rmse, mae, r2) = self.eval_metrics(test_y, predicted_qualities)\n",
        "\n",
        "            # Saving metrics as local\n",
        "            scores = {\"rmse\": rmse, \"mae\": mae, \"r2\": r2}\n",
        "            save_json(path=Path(self.config.metric_file_name), data=scores)\n",
        "\n",
        "            mlflow.log_params(self.config.all_params)\n",
        "\n",
        "            mlflow.log_metric(\"rmse\", rmse)\n",
        "            mlflow.log_metric(\"r2\", r2)\n",
        "            mlflow.log_metric(\"mae\", mae)\n",
        "\n",
        "            # Model registry does not work with file store\n",
        "            if tracking_url_type_store != \"file\":\n",
        "                # Register the model\n",
        "                # There are other ways to use the Model Registry, which depends on the use case,\n",
        "                # please refer to the doc for more information:\n",
        "                # XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
        "                mlflow.sklearn.log_model(model, \"model\", registered_model_name=\"ElasticnetModel\")\n",
        "            else:\n",
        "                mlflow.sklearn.log_model(model, \"model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2025-12-27 15:17:50,394: INFO: common: yaml file: config/config.yaml loaded successfully]\n",
            "[2025-12-27 15:17:50,395: INFO: common: yaml file: params.yaml loaded successfully]\n",
            "[2025-12-27 15:17:50,397: INFO: common: yaml file: schema.yaml loaded successfully]\n",
            "[2025-12-27 15:17:50,397: INFO: common: created directory at: artifacts]\n",
            "[2025-12-27 15:17:50,398: INFO: common: created directory at: artifacts/model_evaluation]\n",
            "[2025-12-27 15:17:51,085: INFO: common: json file saved at: artifacts/model_evaluation/metrics.json]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/charantejakammari/Desktop/DataScience/venv/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\n",
            "  warnings.warn(\n",
            "Successfully registered model 'ElasticnetModel'.\n",
            "2025/12/27 15:17:57 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: ElasticnetModel, version 1\n",
            "Created version '1' of model 'ElasticnetModel'.\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    config = ConfigurationManager()\n",
        "    model_evaluation_config = config.get_model_evaluation_config()\n",
        "    model_evaluation = ModelEvaluation(config=model_evaluation_config)\n",
        "    model_evaluation.log_into_mlflow()\n",
        "except Exception as e:\n",
        "    raise e"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
